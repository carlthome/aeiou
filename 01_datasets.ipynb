{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe09744",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b703b37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b778b6",
   "metadata": {},
   "source": [
    "# datasets\n",
    "> Routines for loading/handling datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9414fc4",
   "metadata": {},
   "source": [
    "Many of these routines are dupes or mods from \"audio-diffusion\" repo by Zach Evans w/ contributions by Scott Hawley https://github.com/zqevans/audio-diffusion/blob/main/diffusion/utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a097942",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb91a8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "from __future__ import annotations  # for type hints, in LAION code samples\n",
    "import numpy as np \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchaudio\n",
    "from torchaudio import transforms as T\n",
    "from torchvision import transforms as VT\n",
    "import random\n",
    "import os\n",
    "import json\n",
    "import tqdm\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from functools import partial\n",
    "from aeiou.core import load_audio, get_audio_filenames, is_silence\n",
    "from fastcore.utils import *\n",
    "import webdataset as wds\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79380ec",
   "metadata": {},
   "source": [
    "## Augmentation routines\n",
    "\n",
    "Not all of these are used.  Code copied from https://github.com/zqevans/audio-diffusion/blob/main/diffusion/utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58789eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class PadCrop(nn.Module):\n",
    "    def __init__(self, \n",
    "        n_samples,           # length of chunk to extract from longer signal\n",
    "        randomize=True,      # draw cropped chunk from a random position in audio file\n",
    "        redraw_silence=True, # a chunk containing silence will be replaced with a new one\n",
    "        silence_thresh=-60,  # threshold in dB below which we declare to be silence\n",
    "        max_redraws=2        # when redrawing silences, don't do it more than this many\n",
    "        ):\n",
    "        super().__init__()\n",
    "        store_attr()     # sets self.___ vars automatically\n",
    "    \n",
    "    def draw_chunk(self, signal):\n",
    "        \"here's the part that actually draws a cropped/padded chunk of audio from signal\"\n",
    "        n, s = signal.shape\n",
    "        start = 0 if (not self.randomize) else torch.randint(0, max(0, s - self.n_samples) + 1, []).item()\n",
    "        end = start + self.n_samples\n",
    "        chunk = signal.new_zeros([n, self.n_samples])\n",
    "        chunk[:, :min(s, self.n_samples)] = signal[:, start:end]\n",
    "        return chunk\n",
    "    \n",
    "    def __call__(self, signal):\n",
    "        \"when part of the pipline, this will grab a padded/cropped chunk from signal\"\n",
    "        chunk = self.draw_chunk(signal)\n",
    "        num_redraws = 0\n",
    "        while self.redraw_silence and is_silence(chunk, thresh=self.silence_thresh) and (num_redraws < self.max_redraws):\n",
    "            #print(f\"    PadCrop: Got silence.  Redrawing. Try {num_redraws+1} of {self.max_redraws}\")\n",
    "            chunk, num_redraws = self.draw_chunk(signal), num_redraws+1\n",
    "        return chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30401d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export    \n",
    "class PhaseFlipper(nn.Module):\n",
    "    \"she was PHAAAAAAA-AAAASE FLIPPER, a random invert yeah\"\n",
    "    def __init__(self, \n",
    "        p=0.5  # probability that phase flip will be applied\n",
    "        ):\n",
    "        super().__init__()\n",
    "        self.p = p\n",
    "    def __call__(self, signal):\n",
    "        return -signal if (random.random() < self.p) else signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad25902",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export  \n",
    "class FillTheNoise(nn.Module):\n",
    "    \"randomly adds a bit of noise, just to spice things up\"\n",
    "    def __init__(self, \n",
    "        p=0.33       # probability that noise will be added\n",
    "        ):\n",
    "        super().__init__()\n",
    "        self.p = p\n",
    "    def __call__(self, signal):\n",
    "        return signal + 0.25*random.random()*(2*torch.rand_like(signal)-1) if (random.random() < self.p) else signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df46c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export    \n",
    "class RandPool(nn.Module):\n",
    "    def __init__(self, p=0.2):\n",
    "        self.p, self.maxkern = p, 100\n",
    "    def __call__(self, signal):\n",
    "        if (random.random() < self.p):\n",
    "            ksize = int(random.random()*self.maxkern)\n",
    "            avger = nn.AvgPool1d(kernel_size=ksize, stride=1, padding=1)\n",
    "            return avger(signal)\n",
    "        else:\n",
    "            return signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a18dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class NormInputs(nn.Module):\n",
    "    \"Normalize inputs to [-1,1]. Useful for quiet inputs\"\n",
    "    def __init__(self, \n",
    "        do_norm=True    # controllable parameter for turning normalization on/off\n",
    "        ):\n",
    "        super().__init__()\n",
    "        self.do_norm = do_norm\n",
    "        self.eps = 1e-2\n",
    "    def __call__(self, signal):\n",
    "        return signal if (not self.do_norm) else signal/(torch.amax(signal,-1)[0] + self.eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37421dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export    \n",
    "class Mono(nn.Module):\n",
    "    \"convert audio to mono\"\n",
    "    def __call__(self, signal):\n",
    "        return torch.mean(signal, dim=0) if len(signal.shape) > 1 else signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc183c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class Stereo(nn.Module):\n",
    "    \"convert audio to stereo\"\n",
    "    def __call__(self, signal):\n",
    "        signal_shape = signal.shape\n",
    "        # Check if it's mono\n",
    "        if len(signal.shape) == 1: # s -> 2, s\n",
    "            signal = signal.unsqueeze(0).repeat(2, 1)\n",
    "        elif len(signal_shape) == 2:\n",
    "            if signal.shape[0] == 1: #1, s -> 2, s\n",
    "                signal = signal.repeat(2, 1)\n",
    "            elif signal.shape[0] > 2: #?, s -> 2,s\n",
    "                signal = signal[:2, :]    \n",
    "        return signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6520c9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export    \n",
    "class RandomGain(nn.Module):\n",
    "    \"apply a random gain to audio\"\n",
    "    def __init__(self, min_gain, max_gain):\n",
    "        super().__init__()\n",
    "        self.min_gain = min_gain\n",
    "        self.max_gain = max_gain\n",
    "\n",
    "    def __call__(self, signal):\n",
    "        gain = random.uniform(self.min_gain, self.max_gain)\n",
    "        signal = signal * gain\n",
    "        return signal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f68f216",
   "metadata": {},
   "source": [
    "## WebDataset support\n",
    "\n",
    "\n",
    "### Background Info\n",
    "cf. https://github.com/webdataset/webdataset\n",
    "\n",
    "> WebDataset makes it easy to write I/O pipelines for large datasets. Datasets can be stored locally or in the cloud.\n",
    "\n",
    "They use the word \"shards\" but never define what \"shard\" means.  I (S.H.) surmise they mean the groups of data files which are gathered into a series of `.tar` files -- the `.tar` files are the shards? \n",
    "\n",
    "cf. Video Tutorial: [\"Loading Training Data with WebDataset\"](https://www.youtube.com/watch?v=mTv_ePYeBhs).\n",
    "\n",
    "The recommended usage for AWS S3 can be seen in [this GitHub Issue comment by tmbdev](https://github.com/webdataset/webdataset/issues/21#issuecomment-706008342):\n",
    "\n",
    "```Python\n",
    "url = \"pipe:s3cmd get s3://bucket/dataset-{000000..000999}.tar -\"\n",
    "dataset = wds.Dataset(url)...\n",
    "```\n",
    "That URL is expecting a contiguously-numbered range of .tar files. So if the file numbers are contiguous (no gaps), then we'll have an easy time. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d13dbdc",
   "metadata": {},
   "source": [
    "### General utility: `get_s3_contents()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a6c47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def get_s3_contents(dataset_path, s3_url_prefix='s3://s-laion-audio/webdataset_tar', filter=''):\n",
    "    \"Gets a list of names of files or subdirectories on an s3 path\"\n",
    "    run_ls = subprocess.run(['aws','s3','ls',f'{s3_url_prefix}/{dataset_path}/'], capture_output=True)\n",
    "    result = subprocess.run(['awk','{print $NF}'],input=run_ls.stdout, capture_output=True)\n",
    "    contents = result.stdout.decode('utf-8').strip().replace('/','').split('\\n')\n",
    "    contents = [x for x in contents if x] # list of non-empty strings\n",
    "    return [x for x in contents if filter in x] # return filtered list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4cff58",
   "metadata": {},
   "source": [
    "Let's test that on the FSD50K dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d5fc76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test', 'train', 'valid']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "get_s3_contents('FSD50K')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6783c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0.tar',\n",
       " '1.tar',\n",
       " '10.tar',\n",
       " '11.tar',\n",
       " '12.tar',\n",
       " '13.tar',\n",
       " '14.tar',\n",
       " '15.tar',\n",
       " '16.tar',\n",
       " '17.tar',\n",
       " '18.tar',\n",
       " '19.tar',\n",
       " '2.tar',\n",
       " '3.tar',\n",
       " '4.tar',\n",
       " '5.tar',\n",
       " '6.tar',\n",
       " '7.tar',\n",
       " '8.tar',\n",
       " '9.tar',\n",
       " 'sizes.json']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "get_s3_contents('FSD50K/test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0c8158",
   "metadata": {},
   "source": [
    "And let's try filtering for only tar files: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6c5ef5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0.tar',\n",
       " '1.tar',\n",
       " '10.tar',\n",
       " '11.tar',\n",
       " '12.tar',\n",
       " '13.tar',\n",
       " '14.tar',\n",
       " '15.tar',\n",
       " '16.tar',\n",
       " '17.tar',\n",
       " '18.tar',\n",
       " '19.tar',\n",
       " '2.tar',\n",
       " '3.tar',\n",
       " '4.tar',\n",
       " '5.tar',\n",
       " '6.tar',\n",
       " '7.tar',\n",
       " '8.tar',\n",
       " '9.tar']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "tar_names = get_s3_contents('FSD50K/test', filter='tar')\n",
    "tar_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd583f1",
   "metadata": {},
   "source": [
    "### For contiguous file-number lists...\n",
    "\n",
    "Maybe the range of tar numbers is contigous. If so, let's have something to output that range:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5317cd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export \n",
    "def get_contiguous_range(\n",
    "    tar_names, # list of tar file names, although the .tar part is actually optional\n",
    "    ):\n",
    "    \"given a string of tar file names, return a string of their range if the numbers are contiguous. Otherwise return empty string\"\n",
    "    if len(tar_names) == 0:  return ''\n",
    "    elif len(tar_names) == 1: return tar_names[-1]\n",
    "    just_nums = [x.replace('.tar','') for x in tar_names]\n",
    "    just_nums.sort(key=int) # sorts numerically but meaningfully preserves leading zeros in strings\n",
    "    nums_arr = np.asarray(just_nums,  dtype=int)\n",
    "    is_contiguous =  np.abs( (nums_arr - np.roll(nums_arr,1)) [1:] ).max() == 1\n",
    "    if is_contiguous:   # {000000..000999}\n",
    "        return '{' + f'{just_nums[0]}..{just_nums[-1]}' +'}'\n",
    "    else:\n",
    "        print(\"get_contiguous_range: File numbers not continuous\")  # have to do more work\n",
    "        return '' # empty string will signify no dice; signal for more work to be done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa0a815",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{0..19}'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "cont_range = get_contiguous_range(tar_names)\n",
    "cont_range"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ff39cb",
   "metadata": {},
   "source": [
    "Test if leading zeros are preserved:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32f3048",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{00000..000019}'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "get_contiguous_range(['0000'+x for x in tar_names])  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da43a691",
   "metadata": {},
   "source": [
    "Test zero-element and single element versions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6748e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(get_contiguous_range([]))\n",
    "print(get_contiguous_range([1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4c1c18",
   "metadata": {},
   "source": [
    "And show that '.tar' is optional:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91055867",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{01..3}'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_contiguous_range(['01','02','3']) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692d1258",
   "metadata": {},
   "source": [
    "....So, if a contiguous range of tar file names is available in a WebDataset directory, then we can just use the native WebDataset creation utilities and can ignore all the other %$#*& that's about to follow below. \n",
    "\n",
    "Let's test the simple version first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bb3eaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pipe:aws s3 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/{0..19}.tar -\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "s3_url_prefix='s3://s-laion-audio/webdataset_tar/'\n",
    "url = f\"pipe:aws s3 cp {s3_url_prefix}FSD50K/test/{cont_range}.tar -\"  # 'aws get' is not a thing. 'aws cp' is\n",
    "print(url)\n",
    "dataset = wds.WebDataset(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f0b2a8",
   "metadata": {},
   "source": [
    "Hooray, it didn't crash! \n",
    "\n",
    "Try dataloader-ing that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f14d1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "\n",
    "## NOTE TO SELF: DON'T RUN THIS ON STABILITY CLUSTER HEADNODE\n",
    "if 'this next part fails' == 'darn it':\n",
    "    loader = wds.WebLoader(dataset, num_workers=4, batch_size=8)\n",
    "    #loader = loader.batched(12)\n",
    "    batch = next(iter(loader))\n",
    "    batch[0].shape, batch[1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8bafe67",
   "metadata": {},
   "source": [
    "### Non-contiguously-numbered lists of tar files...\n",
    "Because you could do a test-train-val split by moving the tar files around.\n",
    "this is what all the extra code is for.\n",
    "\n",
    "A lot of the code predating this was written by LAION who require that the `.json` file(s) for the webdataset(s) be downloaded first. So, let's write a utility for that: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5d9691",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def download_webdataset_json(\n",
    "    datasetnames,              # list of names of valid AudioDataset datasets / paths\n",
    "    dataset_split={},          # keys are dataset names, values are lists of subdirs\n",
    "    src_prefix='s3://s-laion-audio/webdataset_tar', # parent location where the dataset lives\n",
    "    dst_prefix='./json_files', # local path to save the json\n",
    "    force=False,            # Force new download even if local copy exists\n",
    "    ):\n",
    "    \"Downloads the json info of webdataset (sub-)file sizes\"\n",
    "    for dataset_name in datasetnames:\n",
    "        splits = dataset_split if dataset_split!={} else get_s3_contents(dataset_name)\n",
    "        for split in splits:\n",
    "            if not os.path.exists(f\"./json_files/{dataset_name}/{split}\"): # make sure local dir to hold json exists\n",
    "                os.makedirs(f\"./json_files/{dataset_name}/{split}\")\n",
    "            dst = f\"{dst_prefix}/{dataset_name}/{split}/sizes.json\"\n",
    "            if force or not os.path.exists(dst):\n",
    "                os.system(        # TODO: replace os.system with subprocess.run\n",
    "                    f\"aws s3 cp {src_prefix}/{dataset_name}/{split}/sizes.json {dst_prefix}/{dataset_name}/{split}/sizes.json\"\n",
    "                )\n",
    "            #else: print(\"Already got it\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5bc91d",
   "metadata": {},
   "source": [
    "test get_webdataset_json:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4d7f12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://s-laion-audio/webdataset_tar/FSD50K/test/sizes.json to json_files/FSD50K/test/sizes.json\n",
      "download: s3://s-laion-audio/webdataset_tar/FSD50K/train/sizes.json to json_files/FSD50K/train/sizes.json\n",
      "download: s3://s-laion-audio/webdataset_tar/FSD50K/valid/sizes.json to json_files/FSD50K/valid/sizes.json\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "\n",
    "from types import SimpleNamespace\n",
    "args = SimpleNamespace(remotedata=True, datasetnames=['FSD50K'],\n",
    "                       dataset_type=\"webdataset\",\n",
    "                       dataset_proportion=1, datasetpath='IDK')\n",
    "download_webdataset_json(args.datasetnames, force=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd0d12b",
   "metadata": {},
   "source": [
    "For non-contiguous files, we need a list of urls to every single tar file individually.  That's what this next code from LAION's CLAP repo does:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986a2c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tar_path_s3(base_s3_path:str, \n",
    "    train_valid_test:list[str], \n",
    "    dataset_names:list[str]=[''], \n",
    "    cache_path:str='', \n",
    "    recache:bool=False,\n",
    "    ):\n",
    "    \"Code from LAOIN CLAP may not keep. This spits out a list of aws cli calls to download every tar file\"\n",
    "    if os.path.isfile(cache_path) and not recache:\n",
    "        with open(cache_path) as f:\n",
    "            print(\"Loading Cache\")\n",
    "            return json.load(f)\n",
    "\n",
    "    # create cmd for collecting url spesific dataset, \n",
    "    # if `dataset_names` is not given it will search the full base_s3_path\n",
    "    cmds = [f'aws s3 ls s3://{os.path.join(base_s3_path, name, \"\")} --recursive | grep /.*.tar' for name in dataset_names]\n",
    "    # urls are collected\n",
    "    urls = [os.popen(cmd).read() for cmd in cmds]\n",
    "    # cleaning the urls to conform with webdataset\n",
    "    final_urls = [i.split(' ')[-1] for url in urls for i in url.split('\\n')]\n",
    "    final_urls = [f'pipe:aws s3 --cli-connect-timeout 0 cp s3://{os.path.join(base_s3_path, *i.split(\"/\")[1:])} -' for i in final_urls]\n",
    "    # Spliting url by state e.g. train, test and valud\n",
    "    final_urls = {state:[url for url in final_urls if state in url] for state in train_valid_test}\n",
    "\n",
    "    if cache_path:\n",
    "        with open(cache_path, 'w') as f:\n",
    "            json.dump(final_urls, f)\n",
    "\n",
    "    return final_urls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45366e06",
   "metadata": {},
   "source": [
    "Let's grab every tar file in the entire FSD50K dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a89d1e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "urls = {'test': ['pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/0.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/1.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/10.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/11.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/12.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/13.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/14.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/15.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/16.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/17.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/18.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/19.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/2.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/3.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/4.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/5.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/6.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/7.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/8.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/9.tar -'], 'valid': ['pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/valid/0.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/valid/1.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/valid/2.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/valid/3.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/valid/4.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/valid/5.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/valid/6.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/valid/7.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/valid/8.tar -']}\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "urls = get_tar_path_s3('s-laion-audio/webdataset_tar',['test', 'valid'], dataset_names=['FSD50K'])\n",
    "print(\"urls =\",urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4818102",
   "metadata": {},
   "source": [
    "Another version that acheives the same effect: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df110421",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tar_path_from_dataset_name(\n",
    "    dataset_names, dataset_types, islocal,  dataset_path, proportion=1, ):\n",
    "    \"\"\"\n",
    "    From LAOIN\n",
    "    Get tar path from dataset name and type\n",
    "    \"\"\"\n",
    "    if islocal:\n",
    "        output = []\n",
    "        for n in dataset_names:\n",
    "            for s in dataset_types:\n",
    "                tmp = []\n",
    "                sizefilepath_ = f\"./json_files/{n}/{s}/sizes.json\" #  TODO:!!!\n",
    "                if not os.path.exists(sizefilepath_):\n",
    "                    continue\n",
    "                sizes = json.load(open(sizefilepath_, \"r\"))\n",
    "                for k in sizes.keys():\n",
    "                    tmp.append(\n",
    "                        f\"{dataset_path}/{n}/{s}/{k}\"\n",
    "                    )\n",
    "                if proportion!=1:\n",
    "                    tmp = random.sample(tmp, int(proportion * len(tmp)))\n",
    "                output.append(tmp)\n",
    "        return sum(output, [])\n",
    "    else:\n",
    "\n",
    "        output = []\n",
    "        for n in dataset_names:\n",
    "            for s in dataset_types:\n",
    "                tmp = []\n",
    "                sizefilepath_ = f\"./json_files/{n}/{s}/sizes.json\"\n",
    "                if not os.path.exists(sizefilepath_):\n",
    "                    continue\n",
    "                sizes = json.load(open(sizefilepath_, \"r\"))\n",
    "                for k in sizes.keys():\n",
    "                    tmp.append(\n",
    "                        f\"pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/{n}/{s}/{k} -\"\n",
    "                    )\n",
    "                    # TODO: add dataset_path to remote dataset in the future.\n",
    "                if proportion!=1:\n",
    "                    tmp = random.sample(tmp, int(proportion * len(tmp)))\n",
    "                output.append(tmp)\n",
    "                print(\"output= \",output)\n",
    "        return sum(output, [])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa04f1a",
   "metadata": {},
   "source": [
    "Test ^that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a016dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output=  [['pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/0.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/1.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/2.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/3.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/4.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/5.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/6.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/7.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/8.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/9.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/10.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/11.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/12.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/13.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/14.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/15.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/16.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/17.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/18.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/19.tar -']]\n",
      "output=  [['pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/0.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/1.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/2.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/3.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/4.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/5.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/6.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/7.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/8.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/9.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/10.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/11.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/12.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/13.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/14.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/15.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/16.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/17.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/18.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/19.tar -'], ['pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/valid/0.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/valid/1.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/valid/2.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/valid/3.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/valid/4.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/valid/5.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/valid/6.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/valid/7.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/valid/8.tar -']]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/0.tar -',\n",
       " 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/1.tar -',\n",
       " 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/2.tar -',\n",
       " 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/3.tar -',\n",
       " 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/4.tar -',\n",
       " 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/5.tar -',\n",
       " 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/6.tar -',\n",
       " 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/7.tar -',\n",
       " 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/8.tar -',\n",
       " 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/9.tar -',\n",
       " 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/10.tar -',\n",
       " 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/11.tar -',\n",
       " 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/12.tar -',\n",
       " 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/13.tar -',\n",
       " 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/14.tar -',\n",
       " 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/15.tar -',\n",
       " 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/16.tar -',\n",
       " 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/17.tar -',\n",
       " 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/18.tar -',\n",
       " 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/19.tar -',\n",
       " 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/valid/0.tar -',\n",
       " 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/valid/1.tar -',\n",
       " 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/valid/2.tar -',\n",
       " 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/valid/3.tar -',\n",
       " 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/valid/4.tar -',\n",
       " 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/valid/5.tar -',\n",
       " 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/valid/6.tar -',\n",
       " 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/valid/7.tar -',\n",
       " 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/valid/8.tar -']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "\n",
    "train_data_tar_path = get_tar_path_from_dataset_name(\n",
    "    ['FSD50K'],\n",
    "    ['test','valid'],\n",
    "    islocal=False,\n",
    "    proportion=1.0,\n",
    "    dataset_path='/fsx/shawley/data/webdataset',\n",
    ")\n",
    "train_data_tar_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859ae6b9",
   "metadata": {},
   "source": [
    "And now a massive data-pipelining example from LAION that will definitely get modified for this repo: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad2b9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "\n",
    "# taken from LAION CLAP repo, https://github.com/LAION-AI/CLAP/blob/d2d5dae8ea8f1ee02ac40242418a36d1d567943a/src/training/data.py\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class DataInfo:\n",
    "    dataloader: DataLoader\n",
    "    sampler: DistributedSampler\n",
    "        \n",
    "\n",
    "def get_wds_dataset(\n",
    "    args,\n",
    "    model_cfg,\n",
    "    is_train,\n",
    "    audio_ext=\"flac\",\n",
    "    text_ext=\"json\",\n",
    "    max_len=480000,\n",
    "    proportion=1.0,\n",
    "    sizefilepath_=None,\n",
    "    is_local=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Get a dataset for wdsdataloader.\n",
    "    \"\"\"\n",
    "    if is_local is None and (not args.remotedata is None):\n",
    "        is_local = not args.remotedata\n",
    "\n",
    "    input_shards = args.train_data if is_train else args.val_data\n",
    "    assert input_shards is not None\n",
    "\n",
    "    if not sizefilepath_ is None:\n",
    "        sizefilepath = sizefilepath_\n",
    "    else:\n",
    "        sizefilepath = os.path.join(os.path.dirname(input_shards[0]), \"sizes.json\")\n",
    "\n",
    "    if proportion != 1.0:\n",
    "        num_samples, num_shards, input_shards, _ = sample_prop(\n",
    "            sizefilepath, input_shards, proportion, is_local=is_local\n",
    "        )\n",
    "    else:\n",
    "        num_samples, num_shards = get_dataset_size(\n",
    "            input_shards, sizefilepath_=sizefilepath_, is_local=is_local\n",
    "        )\n",
    "\n",
    "    if not num_samples:\n",
    "        if is_train:\n",
    "            num_samples = args.train_num_samples\n",
    "            if not num_samples:\n",
    "                raise RuntimeError(\n",
    "                    \"Currently, number of dataset samples must be specified for training dataset. \"\n",
    "                    \"Please specify via `--train-num-samples` if no dataset length info present.\"\n",
    "                )\n",
    "        else:\n",
    "            num_samples = (\n",
    "                args.val_num_samples or 0\n",
    "            )  # eval will just exhaust the iterator if not specified\n",
    "\n",
    "    pipeline = [wds.SimpleShardList(input_shards)]    # re. Pipeline: cf https://github.com/webdataset/webdataset#pipeline-interface\n",
    "    # at this point we have an iterator over all the shards\n",
    "    if is_train or args.parallel_eval:\n",
    "        pipeline.extend(\n",
    "            [\n",
    "                wds.detshuffle(\n",
    "                    bufsize=_SHARD_SHUFFLE_SIZE,\n",
    "                    initial=_SHARD_SHUFFLE_INITIAL,\n",
    "                    seed=args.seed,\n",
    "                ),\n",
    "                wds.split_by_node,\n",
    "                wds.split_by_worker,\n",
    "                # at this point, we have an iterator over the shards assigned to each worker at each node\n",
    "                wds.tarfile_to_samples(handler=log_and_continue),\n",
    "                wds.shuffle(\n",
    "                    bufsize=_SAMPLE_SHUFFLE_SIZE,\n",
    "                    initial=_SAMPLE_SHUFFLE_INITIAL,\n",
    "                    rng=random.Random(args.seed),\n",
    "                ),\n",
    "                # wds.repeatedly,  # FIXME determine if this is beneficial\n",
    "            ]\n",
    "        )\n",
    "    else:\n",
    "        pipeline.extend(\n",
    "            [\n",
    "                wds.split_by_worker,\n",
    "                # at this point, we have an iterator over the shards assigned to each worker\n",
    "                wds.tarfile_to_samples(handler=log_and_continue),\n",
    "            ]\n",
    "        )\n",
    "    pipeline.append(\n",
    "        wds.map(\n",
    "            partial(\n",
    "                preprocess,\n",
    "                audio_ext=audio_ext,\n",
    "                text_ext=text_ext,\n",
    "                max_len=max_len,\n",
    "                class_index_dict=copy.deepcopy(args.class_index_dict),\n",
    "                data_filling=args.data_filling,\n",
    "            )\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    pipeline.append(\n",
    "        wds.batched(\n",
    "            args.batch_size,\n",
    "            partial=not (is_train or args.parallel_eval),\n",
    "            collation_fn=collate_fn,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    dataset = wds.DataPipeline(*pipeline) # Instantiate list as Pipeline\n",
    "    \n",
    "    if is_train or args.parallel_eval:\n",
    "        # (yusong): Currently parallel evaluation will be not precise as we are repeat the last few samples.\n",
    "        # (yusong): See comments below.\n",
    "        # roll over and repeat a few samples to get same number of full batches on each node\n",
    "        global_batch_size = args.batch_size * args.world_size\n",
    "        num_batches = math.ceil(num_samples / global_batch_size)\n",
    "        num_workers = max(1, args.workers)\n",
    "        num_worker_batches = math.ceil(\n",
    "            num_batches / num_workers\n",
    "        )  # per dataloader worker\n",
    "        num_batches = num_worker_batches * num_workers\n",
    "        num_samples = num_batches * global_batch_size\n",
    "        dataset = dataset.with_epoch(\n",
    "            num_worker_batches\n",
    "        )  # each worker is iterating over this\n",
    "    else:\n",
    "        # last batches are partial, eval is done on single (master) node\n",
    "        num_batches = math.ceil(num_samples / args.batch_size)\n",
    "\n",
    "    kwargs = {}\n",
    "    if args.horovod:  # multi-node training on summit\n",
    "        kwargs[\"multiprocessing_context\"] = \"forkserver\"\n",
    "\n",
    "    dataloader = wds.WebLoader(\n",
    "        dataset, batch_size=None, shuffle=False, num_workers=args.workers, **kwargs\n",
    "    )\n",
    "\n",
    "    # FIXME not clear which approach is better, with_epoch before vs after dataloader?\n",
    "    # hoping to resolve via https://github.com/webdataset/webdataset/issues/169\n",
    "    # if is_train:\n",
    "    #     # roll over and repeat a few samples to get same number of full batches on each node\n",
    "    #     global_batch_size = args.batch_size * args.world_size\n",
    "    #     num_batches = math.ceil(num_samples / global_batch_size)\n",
    "    #     num_workers = max(1, args.workers)\n",
    "    #     num_batches = math.ceil(num_batches / num_workers) * num_workers\n",
    "    #     num_samples = num_batches * global_batch_size\n",
    "    #     dataloader = dataloader.with_epoch(num_batches)\n",
    "    # else:\n",
    "    #     # last batches are partial, eval is done on single (master) node\n",
    "    #     num_batches = math.ceil(num_samples / args.batch_size)\n",
    "\n",
    "    # add meta-data to dataloader instance for convenience\n",
    "    dataloader.num_batches = num_batches\n",
    "    dataloader.num_samples = num_samples\n",
    "\n",
    "    return DataInfo(dataloader, None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8c71f3",
   "metadata": {},
   "source": [
    ".....yeah no tests for that yet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3003418c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "\n",
    "# LAION cut n paste\n",
    "if 'doesnt work yet' == 'stand by':\n",
    "    train_data = get_wds_dataset(    args,\n",
    "        model_cfg,\n",
    "        is_train,\n",
    "        audio_ext=\"flac\",\n",
    "        text_ext=\"json\",\n",
    "        max_len=480000,\n",
    "        proportion=1.0,\n",
    "        sizefilepath_=None,\n",
    "        is_local=False,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf846139",
   "metadata": {},
   "source": [
    "# AudioDataset class\n",
    "\n",
    "The flagship class!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba890cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class AudioDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    Reads from a tree of directories and serves up cropped bits from any and all audio files\n",
    "    found therein. For efficiency, best if you \"chunk\" these files via chunkadelic\n",
    "    modified from https://github.com/drscotthawley/audio-diffusion/blob/main/dataset/dataset.py\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "        paths,             # list of strings of directory (/tree) names to draw audio files from\n",
    "        sample_rate=48000, # audio sample rate in Hz\n",
    "        sample_size=65536, # how many audio samples in each \"chunk\"\n",
    "        random_crop=True,  # take chunks from random positions within files\n",
    "        load_frac=1.0,     # fraction of total dataset to load\n",
    "        cache_training_data=False,  # True = pre-load whole dataset into memory (not fully supported)\n",
    "        num_gpus=8,        # used only when `cache_training_data=True`, to avoid duplicates,\n",
    "        redraw_silence=True, # a chunk containing silence will be replaced with a new one\n",
    "        silence_thresh=-60,  # threshold in dB below which we declare to be silence\n",
    "        max_redraws=2,        # when redrawing silences, don't do it more than this many\n",
    "        augs='Stereo(), PhaseFlipper()', # list of augmentation transforms **after PadCrop**, as a string\n",
    "        verbose=False,       # whether to print notices of reasampling or not\n",
    "        ):\n",
    "        super().__init__()\n",
    "    \n",
    "        print(\"augs =\",augs)\n",
    "        # base_augs are always applied\n",
    "        base_augs = 'PadCrop(sample_size, randomize=random_crop, redraw_silence=redraw_silence, silence_thresh=silence_thresh, max_redraws=max_redraws)'\n",
    "        self.augs = eval(f'torch.nn.Sequential( {base_augs}, {augs} )')  \n",
    "        self.silence_thresh = silence_thresh\n",
    "        self.redraw_silence = redraw_silence\n",
    "        self.max_redraws = max_redraws\n",
    "        self.sr = sample_rate\n",
    "        self.cache_training_data = cache_training_data\n",
    "        self.verbose = verbose\n",
    "\n",
    "        self.filenames = get_audio_filenames(paths)\n",
    "        print(f\"AudioDataset:{len(self.filenames)} files found.\")\n",
    "        self.n_files = int(len(self.filenames)*load_frac)\n",
    "        self.filenames = self.filenames[0:self.n_files]\n",
    "        if cache_training_data: self.preload_files()\n",
    "\n",
    "        self.convert_tensor = VT.ToTensor()\n",
    "\n",
    "    def load_file_ind(self, file_list,i): # used when caching training data\n",
    "        return load_audio(file_list[i], sr=self.sr, verbose=self.verbose).cpu()\n",
    "\n",
    "    def get_data_range(self): # for parallel runs, only grab part of the data -- OBVIATED BY CHUNKING.\n",
    "        start, stop = 0, len(self.filenames)\n",
    "        try:\n",
    "            local_rank = int(os.environ[\"LOCAL_RANK\"])\n",
    "            world_size = int(os.environ[\"WORLD_SIZE\"])\n",
    "            interval = stop//world_size\n",
    "            start, stop = local_rank*interval, (local_rank+1)*interval\n",
    "            return start, stop\n",
    "        except KeyError as e: # we're on GPU 0 and the others haven't been initialized yet\n",
    "            start, stop = 0, len(self.filenames)//self.num_gpus\n",
    "            return start, stop\n",
    "\n",
    "    def preload_files(self):\n",
    "        print(f\"Caching {self.n_files} input audio files:\")\n",
    "        wrapper = partial(self.load_file_ind, self.filenames)\n",
    "        start, stop = self.get_data_range()\n",
    "        with Pool(processes=cpu_count()) as p:   # //8 to avoid FS bottleneck and/or too many processes (b/c * num_gpus)\n",
    "            self.audio_files = list(tqdm.tqdm(p.imap(wrapper, range(start,stop)), total=stop-start))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "    \n",
    "    \n",
    "    def get_next_chunk(self, \n",
    "        idx     # the index of the file within the list of files\n",
    "        ):\n",
    "        \"The heart of this whole dataset routine\"\n",
    "        audio_filename = self.filenames[idx]\n",
    "        try:\n",
    "            if self.cache_training_data:\n",
    "                audio = self.audio_files[idx] # .copy()\n",
    "            else:\n",
    "                audio = load_audio(audio_filename, sr=self.sr, verbose=self.verbose)\n",
    "\n",
    "            #Run augmentations on this sample (including random crop)\n",
    "            if self.augs is not None:\n",
    "                audio = self.augs(audio)\n",
    "                \n",
    "            audio = audio.clamp(-1, 1)\n",
    "            return audio\n",
    "        \n",
    "        except Exception as e:\n",
    "          print(f'Error loading file {audio_filename}: {e}')\n",
    "          return None\n",
    "        \n",
    "        \n",
    "        \n",
    "    def __getitem__(self, \n",
    "        idx     # the index of the file within the list of files\n",
    "        ):\n",
    "        audio = self.get_next_chunk(idx)\n",
    "                \n",
    "        # even with PadCrop set to reject silences, it could be that the whole file is silence; \n",
    "        num_redraws = 0 \n",
    "        while (audio is None) or (self.redraw_silence and is_silence(audio, thresh=self.silence_thresh) \\\n",
    "            and (num_redraws < self.max_redraws)):\n",
    "            #print(f\"AudioDataset.__getitem__: Got None or silence (torch.max = {torch.max(audio)})  Redrawing. Attempt {num_redraws+1} of {self.max_redraws}\")\n",
    "            next_idx = random.randint(0,len(self.filenames)-1)     # pick some other file at random\n",
    "            audio, num_redraws = self.get_next_chunk(next_idx), num_redraws+1\n",
    "               \n",
    "        return self[random.randrange(len(self))] if (audio is None) else audio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91122ae6",
   "metadata": {},
   "source": [
    "Quick check to catch minor errors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c2f993",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = AudioDataset('examples/', augs='Stereo(), PhaseFlipper(), FillTheNoise(), NormInputs()')\n",
    "signal = dataset.__getitem__(0)\n",
    "print(\"signal.shape =\",signal.shape)\n",
    "\n",
    "print(\"\\nStereo -------------\")\n",
    "dataset2 = AudioDataset('examples/', augs='Stereo(), PhaseFlipper()')\n",
    "signal2 = dataset2.__getitem__(0)\n",
    "print(\"signal2.shape =\",signal2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ac8c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev import nbdev_export\n",
    "nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b8b622",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
